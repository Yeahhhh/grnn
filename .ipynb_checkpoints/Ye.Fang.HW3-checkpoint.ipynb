{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## HW 3\n",
    "### Due Apr. 15th by end of day.\n",
    "### Name your notebook by firstname.lastname.hw3.ipynb and email it to zhang@csc.lsu.edu\n",
    "\n",
    "In this HW, we take a look at text processing using RNN based on LSTM. Given a review (hundred to thousand words long) about a movie, we want to classify the review as positive or negative (sentiment analysis). A model is given in this notebook that runs RNN, consisting of a single layer of LSTM cells, on the word sequence of the rewiews. Each review is transformed into a vector, which is the average of the LSTM vectors over the sequence. A softmax layer is then used to classify the reviews based on the LSTM vector representation. \n",
    "\n",
    "Your goal is to train the model and gain some idea on the computation challenge when training \"deep\" model for a large number of iterations.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# for python 2\n",
    "from __future__ import print_function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: pylab import has clobbered these variables: ['test']\n",
      "`%matplotlib` prevents importing * from pylab and numpy\n"
     ]
    }
   ],
   "source": [
    "%pylab inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "import numpy\n",
    "import theano\n",
    "import theano.tensor as T\n",
    "\n",
    "from lstm import load_data, prepare_data, batches_idx, lstm_layer, rmsprop"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model meta parameters\n",
    "\n",
    " - n_hidden: # of neurons in the LSTM layer\n",
    " - n_words: # of words in the dictionary. We use most frequent words. All other words are treated as unknown.\n",
    " - n_sample: max size (# of reviews) of the train dataset and the test dataset. (We may not be able to reach the max because if we want only reviews up to 50 words, there may be less than max such reviews in the whole data collection.)  \n",
    " - maxlen: max length in number of words for a review to be considered. Review longer than this will be ignored. This is also the # of recurrent steps.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "n_sample = 1000\n",
    "maxlen = 50\n",
    "n_words = 40\n",
    "train, test, translate = load_data('./', n_words, n_sample, maxlen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "raw",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv('./input/dsame_format2/1000.csv')\n",
    "feature = df.ix[:,:-1].values.tolist()\n",
    "label = df.ix[:,-1].values.tolist()\n",
    "train = (feature, label)\n",
    "\n",
    "df = pd.read_csv('./input/dsame_format2/100.csv')\n",
    "feature = df.ix[:,:-1].values.tolist()\n",
    "label = df.ix[:,-1].values.tolist()\n",
    "test = (feature, label)\n",
    "\n",
    "n_words=6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#test[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(train[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "n_hidden=50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num of pos in train: 169 out of 269\n",
      "num of pos in test: 163 out of 293\n"
     ]
    }
   ],
   "source": [
    "print('num of pos in train:', numpy.sum(train[1]), 'out of', len(train[1]))\n",
    "print('num of pos in test:', numpy.sum(test[1]), 'out of', len(test[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def build_model(n_hidden, n_words):\n",
    "\n",
    "    x = T.matrix('x', dtype='int64')\n",
    "    mask = T.matrix('mask', dtype='float64')\n",
    "    y = T.vector('y', dtype='int64')\n",
    "\n",
    "    # embedding params\n",
    "    randn = numpy.random.rand(n_words, n_hidden)\n",
    "    Wemb = theano.shared(0.01 * randn)\n",
    "    \n",
    "    #lstm layer\n",
    "    lstm = lstm_layer(n_hidden)\n",
    "    \n",
    "    # classifier params\n",
    "    CU = theano.shared(0.01 * numpy.random.randn(n_hidden, 2))\n",
    "    Cb = theano.shared(numpy.zeros((2,)))\n",
    "    params = lstm.params + [Wemb, CU, Cb]\n",
    "    \n",
    "    \n",
    "    n_timesteps = x.shape[0]\n",
    "    n_samples = x.shape[1]\n",
    "\n",
    "    emb = Wemb[x.flatten()].reshape([n_timesteps, n_samples, n_hidden])\n",
    "    proj = lstm.calc_lstm(emb, mask)\n",
    "    proj = (proj * mask[:, :, None]).sum(axis=0)\n",
    "    proj = proj / mask.sum(axis=0)[:, None]\n",
    "\n",
    "    pred = T.nnet.softmax(T.dot(proj, CU) + Cb)\n",
    "\n",
    "    f_pred = theano.function([x, mask], pred.argmax(axis=1), name='f_pred')\n",
    "\n",
    "    off = 1e-8\n",
    "    cost = -T.log(pred[T.arange(n_samples), y] + off).mean()\n",
    "\n",
    "    return x, mask, y, params, cost, f_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "When compiling the inner function of scan the following error has been encountered: The initial state (`outputs_info` in scan nomenclature) of variable IncSubtensor{Set;:int64:}.0 (argument number 2) has dtype float32, while the result of the inner function (`fn`) has dtype float64. This can happen if the inner function of scan results in an upcast or downcast.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-104-785eb0b6dbe5>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmask\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcost\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mf_pred\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbuild_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn_hidden\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_words\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mgrads\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mT\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgrad\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcost\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mlr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mT\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mscalar\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'lr'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mf_grad_shared\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mf_update\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrmsprop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgrads\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmask\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcost\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-103-646721ceabcc>\u001b[0m in \u001b[0;36mbuild_model\u001b[1;34m(n_hidden, n_words)\u001b[0m\n\u001b[0;32m     22\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     23\u001b[0m     \u001b[0memb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mWemb\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mn_timesteps\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_samples\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_hidden\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 24\u001b[1;33m     \u001b[0mproj\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlstm\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcalc_lstm\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0memb\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmask\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     25\u001b[0m     \u001b[0mproj\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mproj\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mmask\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mNone\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     26\u001b[0m     \u001b[0mproj\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mproj\u001b[0m \u001b[1;33m/\u001b[0m \u001b[0mmask\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mNone\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/csc7700/proj/lstm.py\u001b[0m in \u001b[0;36mcalc_lstm\u001b[1;34m(self, input, mask)\u001b[0m\n\u001b[0;32m    132\u001b[0m                                                       n_samples, self.n_hidden),\n\u001b[0;32m    133\u001b[0m                                               T.alloc(numpy.asarray(0., dtype=numpy.float32),\n\u001b[1;32m--> 134\u001b[1;33m                                                       n_samples, self.n_hidden)])\n\u001b[0m\u001b[0;32m    135\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    136\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mrval\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/csc7700/app/anaconda2/lib/python2.7/site-packages/theano/scan_module/scan.pyc\u001b[0m in \u001b[0;36mscan\u001b[1;34m(fn, sequences, outputs_info, non_sequences, n_steps, truncate_gradient, go_backwards, mode, name, profile, allow_gc, strict)\u001b[0m\n\u001b[0;32m   1039\u001b[0m             \u001b[1;32mpass\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1040\u001b[0m         \u001b[0mscan_inputs\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0marg\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1041\u001b[1;33m     \u001b[0mscan_outs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlocal_op\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mscan_inputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1042\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mscan_outs\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32min\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1043\u001b[0m         \u001b[0mscan_outs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mscan_outs\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/csc7700/app/anaconda2/lib/python2.7/site-packages/theano/gof/op.pyc\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *inputs, **kwargs)\u001b[0m\n\u001b[0;32m    609\u001b[0m         \"\"\"\n\u001b[0;32m    610\u001b[0m         \u001b[0mreturn_list\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'return_list'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 611\u001b[1;33m         \u001b[0mnode\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmake_node\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    612\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    613\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mconfig\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcompute_test_value\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[1;34m'off'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/csc7700/app/anaconda2/lib/python2.7/site-packages/theano/scan_module/scan_op.pyc\u001b[0m in \u001b[0;36mmake_node\u001b[1;34m(self, *inputs)\u001b[0m\n\u001b[0;32m    536\u001b[0m                                   \u001b[0margoffset\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0midx\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    537\u001b[0m                                   \u001b[0mouter_sitsot\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtype\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 538\u001b[1;33m                                   inner_sitsot_out.type.dtype))\n\u001b[0m\u001b[0;32m    539\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0minner_sitsot_out\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[0mouter_sitsot\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[1;33m-\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    540\u001b[0m                 raise ValueError(err_msg3 %\n",
      "\u001b[1;31mValueError\u001b[0m: When compiling the inner function of scan the following error has been encountered: The initial state (`outputs_info` in scan nomenclature) of variable IncSubtensor{Set;:int64:}.0 (argument number 2) has dtype float32, while the result of the inner function (`fn`) has dtype float64. This can happen if the inner function of scan results in an upcast or downcast."
     ]
    }
   ],
   "source": [
    "(x, mask, y, params, cost, f_pred) = build_model(n_hidden, n_words)\n",
    "grads = T.grad(cost, params)    \n",
    "\n",
    "lr = T.scalar(name='lr')\n",
    "f_grad_shared, f_update = rmsprop(lr, params, grads, x, mask, y, cost)\n",
    "\n",
    "lrate=0.1\n",
    "updates = [(p, p - lrate * g) for p, g in zip(params, grads)]\n",
    "f_sgd = theano.function([x, mask, y], cost, updates=updates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "nepoch = 300\n",
    "#nepoch = 5000\n",
    "cc = numpy.zeros((nepoch,))\n",
    "\n",
    "sampling_iter = 10\n",
    "nepoch2 = int(nepoch / sampling_iter)\n",
    "cc2 = numpy.zeros((nepoch2,))\n",
    "cc2_idx = numpy.zeros((nepoch2,))\n",
    "\n",
    "\n",
    "\n",
    "t0 = time.time()\n",
    "for i in range(nepoch):\n",
    "    cost = 0\n",
    "    for train_index in batches_idx(len(train[0]), 500):\n",
    "        y = [train[1][t] for t in train_index]\n",
    "        x = [train[0][t] for t in train_index]\n",
    "        x, mask, y = prepare_data(x, y)\n",
    "        \n",
    "        cost += f_grad_shared(x, mask, y)\n",
    "        f_update(lrate)\n",
    "        #cost += f_sgd(x, mask, y)\n",
    "    \n",
    "    cc[i] = cost\n",
    "  \n",
    "\n",
    "    if i % sampling_iter == 0:\n",
    "        tx2, tmask2, ty2 = prepare_data(test[0], test[1])\n",
    "        py2 = f_pred(tx2, tmask2)\n",
    "        err_rate = 1.0*numpy.sum(numpy.abs(ty2 - py2))/len(test[0])\n",
    "        i2 = int(i / sampling_iter)\n",
    "        cc2[i2] = err_rate\n",
    "        cc2_idx[i2] = i\n",
    "        #print(i, err_rate)\n",
    "\n",
    "\n",
    "print('')\n",
    "print('run time:', (time.time()-t0)/60.0, \"minutes\")  #training time in min."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#print(cc)\n",
    "plot(cc[20:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(cc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#print(cc2)\n",
    "#print(cc2_idx)\n",
    "plot(cc2_idx, cc2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "np.min(cc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_err(data):\n",
    "    tx, tmask, ty = prepare_data(data[0], data[1])\n",
    "    py = f_pred(tx, tmask)\n",
    "    err_rate = 1.0*numpy.sum(numpy.abs(ty - py))/len(data[0])\n",
    "    return err_rate\n",
    "\n",
    "\n",
    "print(get_err(train))\n",
    "print(get_err(test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def benchmark1(n_hidden = 10, n_words = 500, n_sample = 1000, maxlen = 50):\n",
    "    ########################\n",
    "    train, test, translate = load_data('./', n_words, n_sample, maxlen)\n",
    "\n",
    "    \n",
    "    ########################    \n",
    "    (x, mask, y, params, cost, f_pred) = build_model(n_hidden, n_words)\n",
    "    grads = T.grad(cost, params)    \n",
    "\n",
    "    lr = T.scalar(name='lr')\n",
    "    f_grad_shared, f_update = rmsprop(lr, params, grads, x, mask, y, cost)\n",
    "\n",
    "    lrate=0.1\n",
    "    updates = [(p, p - lrate * g) for p, g in zip(params, grads)]\n",
    "    f_sgd = theano.function([x, mask, y], cost, updates=updates)\n",
    "\n",
    "    \n",
    "    ########################\n",
    "    nepoch = 500\n",
    "    cc = numpy.zeros((nepoch,))\n",
    "    t0 = time.time()\n",
    "    for i in range(nepoch):\n",
    "        cost = 0\n",
    "        for train_index in batches_idx(len(train[0]), 100):\n",
    "            y = [train[1][t] for t in train_index]\n",
    "            x = [train[0][t]for t in train_index]\n",
    "            x, mask, y = prepare_data(x, y)\n",
    "\n",
    "            cost += f_grad_shared(x, mask, y)\n",
    "            f_update(lrate)\n",
    "            #cost += f_sgd(x, mask, y)\n",
    "\n",
    "        cc[i] = cost\n",
    "        #print('iteration:', i, 'cost=', cost)\n",
    "        #if i % 10 == 0:\n",
    "            #print(i, end = ' ')\n",
    "    print('')\n",
    "    t1 = time.time()\n",
    "    ts = (t1 - t0) / 60.0 # training time in min\n",
    "    return ts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ts = benchmark1()\n",
    "print(ts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 1\n",
    "Investigate test error rate with respect to training iterations. \n",
    "\n",
    "  - Plot error rate for test data v.s. number of iterations.  \n",
    "  \n",
    "Train the model until \"cost\" gets close to 0 (smaller than 0.01). You don't need to get error rate every iteration. Rather, every 250 or 500 iterations, call f_pred to make prediction on the test data and calculated error rate (an example is given above for prediction and error rate calculation).\n",
    "\n",
    "### Make plot on this notebook and submit the notebook with the plot. I'd like to see the plot besides your code.\n",
    "### DONE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "nepoch = 10000\n",
    "cc = numpy.zeros((nepoch,))\n",
    "\n",
    "sampling_iter = 100 # get error rate every 100 iterations\n",
    "nepoch2 = int(nepoch / sampling_iter)\n",
    "cc2 = numpy.zeros((nepoch2,))\n",
    "cc2_idx = numpy.zeros((nepoch2,))\n",
    "\n",
    "\n",
    "t0 = time.time()\n",
    "for i in range(nepoch):\n",
    "    cost = 0\n",
    "    for train_index in batches_idx(len(train[0]), 100):\n",
    "        y = [train[1][t] for t in train_index]\n",
    "        x = [train[0][t] for t in train_index]\n",
    "        x, mask, y = prepare_data(x, y)\n",
    "        \n",
    "        cost += f_grad_shared(x, mask, y)\n",
    "        f_update(lrate)\n",
    "        #cost += f_sgd(x, mask, y)\n",
    "    \n",
    "    cc[i] = cost\n",
    "    if i % 100 == 0:\n",
    "        print(i, end = ' ')\n",
    "        #print(i)\n",
    "\n",
    "    if i % sampling_iter == 0:\n",
    "        tx2, tmask2, ty2 = prepare_data(test[0], test[1])\n",
    "        py2 = f_pred(tx2, tmask2)\n",
    "        err_rate = 1.0*numpy.sum(numpy.abs(ty2 - py2))/len(test[0])\n",
    "        i2 = int(i / sampling_iter)\n",
    "        cc2[i2] = err_rate\n",
    "        cc2_idx[i2] = i\n",
    "        #print(i, err_rate)\n",
    "\n",
    "print('')\n",
    "print('run time:', (time.time()-t0)/60.0, \"minutes\")  #training time in min."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(\"training cost of the last 20 iterations:\")\n",
    "print(cc[-20:])\n",
    "\n",
    "print(\"training cost (y) / iterations (x):\")\n",
    "plot(cc[20:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(\"testing error rate (y) / iterations (x):\")\n",
    "plot(cc2_idx, cc2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "nepoch = 2500\n",
    "cc = numpy.zeros((nepoch,))\n",
    "\n",
    "sampling_iter = 10 # get error rate every 10 iterations\n",
    "nepoch2 = int(nepoch / sampling_iter)\n",
    "cc2 = numpy.zeros((nepoch2,))\n",
    "cc2_idx = numpy.zeros((nepoch2,))\n",
    "\n",
    "\n",
    "t0 = time.time()\n",
    "for i in range(nepoch):\n",
    "    cost = 0\n",
    "    for train_index in batches_idx(len(train[0]), 100):\n",
    "        y = [train[1][t] for t in train_index]\n",
    "        x = [train[0][t] for t in train_index]\n",
    "        x, mask, y = prepare_data(x, y)\n",
    "        \n",
    "        cost += f_grad_shared(x, mask, y)\n",
    "        f_update(lrate)\n",
    "        #cost += f_sgd(x, mask, y)\n",
    "    \n",
    "    cc[i] = cost\n",
    "    if i % 100 == 0:\n",
    "        print(i, end = ' ')\n",
    "        #print(i)\n",
    "\n",
    "    if i % sampling_iter == 0:\n",
    "        tx2, tmask2, ty2 = prepare_data(test[0], test[1])\n",
    "        py2 = f_pred(tx2, tmask2)\n",
    "        err_rate = 1.0*numpy.sum(numpy.abs(ty2 - py2))/len(test[0])\n",
    "        i2 = int(i / sampling_iter)\n",
    "        cc2[i2] = err_rate\n",
    "        cc2_idx[i2] = i\n",
    "        #print(i, err_rate)\n",
    "\n",
    "print('')\n",
    "print('run time:', (time.time()-t0)/60.0, \"minutes\")  #training time in min."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(\"training cost of the last 20 iterations:\")\n",
    "print(cc[-20:])\n",
    "\n",
    "print(\"training cost (y) / iterations (x):\")\n",
    "plot(cc[20:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(\"testing error rate (y) / iterations (x):\")\n",
    "plot(cc2_idx, cc2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 2\n",
    "Investigate training time with respect to the following parameters:\n",
    "  - n_hidden (# of neurons in the LSTM layer)\n",
    "  - maxlen (max length in number of words for a review), i.e., # of recurrent steps\n",
    "\n",
    "Fix the number of training iterations (i.e., 200), vary (increase the values of) the parameters and measure the training time. (Don't make small changes of values, e.g., from 10 to 11. You should make significant change of the values, e.g., from 10 to 20 to 50 to 100 etc.) Try several values and make the following plots: \n",
    "  - training time v.s. n_hidden\n",
    "  - training time v.s. maxlen\n",
    "  \n",
    "### Make plot on this notebook and submit the notebook with the plot. I'd like to see the plot besides your code.\n",
    "### DONE\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "n_hidden = []\n",
    "n_hidden_log2 = []\n",
    "training_time = []\n",
    "\n",
    "for i in range(1, 9):\n",
    "    para = 2 ** i\n",
    "    #ts = 1\n",
    "    ts = benchmark1(n_hidden=para, n_words = 500, n_sample = 1000, maxlen = 50)\n",
    "    print(para, end = ' ')\n",
    "    n_hidden.append(para)\n",
    "    n_hidden_log2.append(i)\n",
    "    training_time.append(ts)\n",
    "print('')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(training_time)\n",
    "print(n_hidden)\n",
    "plt.ylabel('training time (minutes)')\n",
    "plt.xlabel('n_hidden:')\n",
    "plot(n_hidden, training_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "maxlen2 = []\n",
    "maxlen2_log2 = []\n",
    "training2_time = []\n",
    "\n",
    "for i in range(1, 8):\n",
    "    para = 2 ** i\n",
    "    #ts = 1\n",
    "    ts = benchmark1(n_hidden=10, n_words = 500, n_sample = 1000, maxlen = para)\n",
    "    print(para, end = ' ')\n",
    "    maxlen2.append(para)\n",
    "    maxlen2_log2.append(i)\n",
    "    training2_time.append(ts)\n",
    "print('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(training2_time)\n",
    "print(maxlen2)\n",
    "plt.ylabel('training time (minutes)')\n",
    "plt.xlabel('maxlen')\n",
    "plot(maxlen2, training2_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
