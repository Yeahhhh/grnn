{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## HW 3\n",
    "### Due Apr. 15th by end of day.\n",
    "### Name your notebook by firstname.lastname.hw3.ipynb and email it to zhang@csc.lsu.edu\n",
    "\n",
    "In this HW, we take a look at text processing using RNN based on LSTM. Given a review (hundred to thousand words long) about a movie, we want to classify the review as positive or negative (sentiment analysis). A model is given in this notebook that runs RNN, consisting of a single layer of LSTM cells, on the word sequence of the rewiews. Each review is transformed into a vector, which is the average of the LSTM vectors over the sequence. A softmax layer is then used to classify the reviews based on the LSTM vector representation. \n",
    "\n",
    "Your goal is to train the model and gain some idea on the computation challenge when training \"deep\" model for a large number of iterations.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# for python 2\n",
    "from __future__ import print_function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "%pylab inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "import numpy as np\n",
    "import theano\n",
    "import theano.tensor as T\n",
    "\n",
    "from lstm import load_data, prepare_data, batches_idx, lstm_layer, rmsprop\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model meta parameters\n",
    "\n",
    " - n_hidden: # of neurons in the LSTM layer\n",
    " - n_words: # of words in the dictionary. We use most frequent words. All other words are treated as unknown.\n",
    " - n_sample: max size (# of reviews) of the train dataset and the test dataset. (We may not be able to reach the max because if we want only reviews up to 50 words, there may be less than max such reviews in the whole data collection.)  \n",
    " - maxlen: max length in number of words for a review to be considered. Review longer than this will be ignored. This is also the # of recurrent steps.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "raw",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "n_words = 500\n",
    "n_sample = 1000\n",
    "maxlen = 50\n",
    "train, test, translate = load_data('./', n_words, n_sample, maxlen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(100000, 41)\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('../input/len20/a.raw.mod_para1_err1.format2')\n",
    "#df = df.iloc[np.random.permutation(len(df))]\n",
    "print(df.shape)\n",
    "\n",
    "ntrain=500\n",
    "ntest=100\n",
    "\n",
    "d = df[0:ntrain]\n",
    "train = (d.ix[:,:-1].values.tolist(), d.ix[:,-1].values.tolist())\n",
    "\n",
    "d = df[ntrain:ntrain+ntest]\n",
    "test = (d.ix[:,:-1].values.tolist(), d.ix[:,-1].values.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num of pos in train: 260 out of 500\n",
      "num of pos in test: 56 out of 100\n"
     ]
    }
   ],
   "source": [
    "print('num of pos in train:', numpy.sum(train[1]), 'out of', len(train[1]))\n",
    "print('num of pos in test:', numpy.sum(test[1]), 'out of', len(test[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "n_hidden=1\n",
    "n_words=7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def build_model(n_hidden, n_words):\n",
    "\n",
    "    x = T.matrix('x', dtype='int64')\n",
    "    mask = T.matrix('mask', dtype='float64')\n",
    "    y = T.vector('y', dtype='int64')\n",
    "\n",
    "    # embedding params\n",
    "    randn = numpy.random.rand(n_words, n_hidden)\n",
    "    Wemb = theano.shared(0.01 * randn)\n",
    "    \n",
    "    #lstm layer\n",
    "    lstm = lstm_layer(n_hidden)\n",
    "    \n",
    "    # classifier params\n",
    "    CU = theano.shared(0.01 * numpy.random.randn(n_hidden, 2))\n",
    "    Cb = theano.shared(numpy.zeros((2,)))\n",
    "    params = lstm.params + [Wemb, CU, Cb]\n",
    "    \n",
    "    \n",
    "    n_timesteps = x.shape[0]\n",
    "    n_samples = x.shape[1]\n",
    "\n",
    "    emb = Wemb[x.flatten()].reshape([n_timesteps, n_samples, n_hidden])\n",
    "    proj = lstm.calc_lstm(emb, mask)\n",
    "    proj = (proj * mask[:, :, None]).sum(axis=0)\n",
    "    proj = proj / mask.sum(axis=0)[:, None]\n",
    "\n",
    "    pred = T.nnet.softmax(T.dot(proj, CU) + Cb)\n",
    "\n",
    "    f_pred = theano.function([x, mask], pred.argmax(axis=1), name='f_pred')\n",
    "\n",
    "    off = 1e-8\n",
    "    cost = -T.log(pred[T.arange(n_samples), y] + off).mean()\n",
    "\n",
    "    return x, mask, y, params, cost, f_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Cannot convert Type TensorType(float64, (False, True, True)) (of Variable IncSubtensor{Set;:int64:}.0) into Type TensorType(float64, (False, False, True)). You can try to manually convert IncSubtensor{Set;:int64:}.0 into a TensorType(float64, (False, False, True)).",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-9-785eb0b6dbe5>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmask\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcost\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mf_pred\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbuild_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn_hidden\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_words\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mgrads\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mT\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgrad\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcost\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mlr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mT\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mscalar\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'lr'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mf_grad_shared\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mf_update\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrmsprop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgrads\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmask\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcost\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-8-d10cc40d4721>\u001b[0m in \u001b[0;36mbuild_model\u001b[1;34m(n_hidden, n_words)\u001b[0m\n\u001b[0;32m     22\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     23\u001b[0m     \u001b[0memb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mWemb\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mn_timesteps\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_samples\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_hidden\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 24\u001b[1;33m     \u001b[0mproj\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlstm\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcalc_lstm\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0memb\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmask\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     25\u001b[0m     \u001b[0mproj\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mproj\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mmask\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mNone\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     26\u001b[0m     \u001b[0mproj\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mproj\u001b[0m \u001b[1;33m/\u001b[0m \u001b[0mmask\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mNone\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/yfang11/mnt/fs_zp1work/course/lsu/2016spring_csc7700_deap_learning/proj/format1_leng20_err1_500_100__different_RNN/lstm.pyc\u001b[0m in \u001b[0;36mcalc_lstm\u001b[1;34m(self, input, mask)\u001b[0m\n\u001b[0;32m    132\u001b[0m                                                       n_samples, self.n_hidden),\n\u001b[0;32m    133\u001b[0m                                               T.alloc(numpy.asarray(0., dtype=numpy.float64),\n\u001b[1;32m--> 134\u001b[1;33m                                                       n_samples, self.n_hidden)])\n\u001b[0m\u001b[0;32m    135\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    136\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mrval\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/yfang11/app/_anaconda_2/lib/python2.7/site-packages/theano/scan_module/scan.pyc\u001b[0m in \u001b[0;36mscan\u001b[1;34m(fn, sequences, outputs_info, non_sequences, n_steps, truncate_gradient, go_backwards, mode, name, profile, allow_gc, strict)\u001b[0m\n\u001b[0;32m   1040\u001b[0m             \u001b[1;32mpass\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1041\u001b[0m         \u001b[0mscan_inputs\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0marg\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1042\u001b[1;33m     \u001b[0mscan_outs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlocal_op\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mscan_inputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1043\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mscan_outs\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32min\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1044\u001b[0m         \u001b[0mscan_outs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mscan_outs\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/yfang11/app/_anaconda_2/lib/python2.7/site-packages/theano/gof/op.pyc\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *inputs, **kwargs)\u001b[0m\n\u001b[0;32m    505\u001b[0m         \"\"\"\n\u001b[0;32m    506\u001b[0m         \u001b[0mreturn_list\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'return_list'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 507\u001b[1;33m         \u001b[0mnode\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmake_node\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    508\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    509\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mconfig\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcompute_test_value\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[1;34m'off'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/yfang11/app/_anaconda_2/lib/python2.7/site-packages/theano/scan_module/scan_op.pyc\u001b[0m in \u001b[0;36mmake_node\u001b[1;34m(self, *inputs)\u001b[0m\n\u001b[0;32m    355\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mouter_sitsot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    356\u001b[0m                 self.inner_sitsot_outs(self.outputs))):\n\u001b[1;32m--> 357\u001b[1;33m             \u001b[0mouter_sitsot\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_outer_sitsot\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mas_var\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minner_sitsot\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    358\u001b[0m             \u001b[0mnew_inputs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mouter_sitsot\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    359\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0minner_sitsot\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[0mouter_sitsot\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[1;33m-\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/yfang11/app/_anaconda_2/lib/python2.7/site-packages/theano/scan_module/scan_op.pyc\u001b[0m in \u001b[0;36mformat\u001b[1;34m(var, as_var)\u001b[0m\n\u001b[0;32m    256\u001b[0m                     broadcastable=(tuple(var.broadcastable[:1]) +\n\u001b[0;32m    257\u001b[0m                                    tuple(as_var.broadcastable)))\n\u001b[1;32m--> 258\u001b[1;33m                 \u001b[0mrval\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtmp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfilter_variable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrval\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    259\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mrval\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    260\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/yfang11/app/_anaconda_2/lib/python2.7/site-packages/theano/tensor/type.pyc\u001b[0m in \u001b[0;36mfilter_variable\u001b[1;34m(self, other)\u001b[0m\n\u001b[0;32m    216\u001b[0m                     \u001b[0mothertype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mother\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtype\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    217\u001b[0m                     \u001b[0mother\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mother\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 218\u001b[1;33m                     self=self)\n\u001b[0m\u001b[0;32m    219\u001b[0m                 )\n\u001b[0;32m    220\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: Cannot convert Type TensorType(float64, (False, True, True)) (of Variable IncSubtensor{Set;:int64:}.0) into Type TensorType(float64, (False, False, True)). You can try to manually convert IncSubtensor{Set;:int64:}.0 into a TensorType(float64, (False, False, True))."
     ]
    }
   ],
   "source": [
    "(x, mask, y, params, cost, f_pred) = build_model(n_hidden, n_words)\n",
    "grads = T.grad(cost, params)    \n",
    "\n",
    "lr = T.scalar(name='lr')\n",
    "f_grad_shared, f_update = rmsprop(lr, params, grads, x, mask, y, cost)\n",
    "\n",
    "lrate=0.1\n",
    "updates = [(p, p - lrate * g) for p, g in zip(params, grads)]\n",
    "f_sgd = theano.function([x, mask, y], cost, updates=updates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#nepoch = 200\n",
    "nepoch = 10000\n",
    "cc = numpy.zeros((nepoch,))\n",
    "\n",
    "sampling_iter = 50\n",
    "nepoch2 = int(nepoch / sampling_iter)\n",
    "cc2 = numpy.zeros((nepoch2,))\n",
    "cc2_idx = numpy.zeros((nepoch2,))\n",
    "\n",
    "\n",
    "\n",
    "t0 = time.time()\n",
    "for i in range(nepoch):\n",
    "    cost = 0\n",
    "    for train_index in batches_idx(len(train[0]), 200):\n",
    "        y = [train[1][t] for t in train_index]\n",
    "        x = [train[0][t] for t in train_index]\n",
    "        x, mask, y = prepare_data(x, y)\n",
    "        \n",
    "        cost += f_grad_shared(x, mask, y)\n",
    "        f_update(lrate)\n",
    "        #cost += f_sgd(x, mask, y)\n",
    "    \n",
    "    cc[i] = cost\n",
    "    if i % 10 == 0:\n",
    "        print(i, cost, end = ' ')\n",
    "        #print(i)\n",
    "\n",
    "    if i % sampling_iter == 0:\n",
    "        tx2, tmask2, ty2 = prepare_data(test[0], test[1])\n",
    "        py2 = f_pred(tx2, tmask2)\n",
    "        err_rate = 1.0*numpy.sum(numpy.abs(ty2 - py2))/len(test[0])\n",
    "        i2 = int(i / sampling_iter)\n",
    "        cc2[i2] = err_rate\n",
    "        cc2_idx[i2] = i\n",
    "        #print(i, err_rate)\n",
    "\n",
    "\n",
    "print('')\n",
    "print('run time:', (time.time()-t0)/60.0, \"minutes\")  #training time in min."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plot(cc[20:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "nx = 2\n",
    "ny = 1\n",
    "fig = plt.figure(figsize = [6 * nx, 4 * ny]) # inch\n",
    "\n",
    "ax0 = fig.add_subplot(ny, nx, 1)\n",
    "plot(cc)\n",
    "plt.legend(['training score'], loc='lower left')\n",
    "ax0.set_xlim(0)\n",
    "ax0.set_ylim(0)\n",
    "ax0.set_ylabel('training score')\n",
    "ax0.set_xlabel('epoch')\n",
    "\n",
    "ax1 = fig.add_subplot(ny, nx, 2)\n",
    "plot(cc2_idx, cc2, color='g')\n",
    "plt.legend(['test error'], loc='lower left')\n",
    "ax1.set_xlim(0)\n",
    "ax1.set_ylim(0, 1)\n",
    "ax1.set_ylabel('testing error')\n",
    "ax1.set_xlabel('epoch')\n",
    "\n",
    "fig.tight_layout()\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "nx = 2\n",
    "ny = 1\n",
    "fig = plt.figure(figsize = [6 * nx, 4 * ny]) # inch\n",
    "\n",
    "ax0 = fig.add_subplot(ny, nx, 1)\n",
    "plot(cc, color='b')\n",
    "#plt.legend(['training score'], loc='lower left')\n",
    "ax0.set_xlim(0)\n",
    "ax0.set_ylim(0)\n",
    "ax0.set_ylabel('training score', color='b')\n",
    "ax0.set_xlabel('epoch')\n",
    "\n",
    "ax1 = ax0.twinx()\n",
    "plot(cc2_idx, cc2, color='g')\n",
    "#plt.legend(['test error'], loc='lower left')\n",
    "ax1.set_xlim(0)\n",
    "ax1.set_ylim(0, 1)\n",
    "ax1.set_ylabel('testing error', color='g')\n",
    "ax1.set_xlabel('epoch')\n",
    "\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
