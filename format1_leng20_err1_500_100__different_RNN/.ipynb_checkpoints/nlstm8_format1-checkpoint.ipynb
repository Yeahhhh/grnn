{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## HW 3\n",
    "### Due Apr. 15th by end of day.\n",
    "### Name your notebook by firstname.lastname.hw3.ipynb and email it to zhang@csc.lsu.edu\n",
    "\n",
    "In this HW, we take a look at text processing using RNN based on LSTM. Given a review (hundred to thousand words long) about a movie, we want to classify the review as positive or negative (sentiment analysis). A model is given in this notebook that runs RNN, consisting of a single layer of LSTM cells, on the word sequence of the rewiews. Each review is transformed into a vector, which is the average of the LSTM vectors over the sequence. A softmax layer is then used to classify the reviews based on the LSTM vector representation. \n",
    "\n",
    "Your goal is to train the model and gain some idea on the computation challenge when training \"deep\" model for a large number of iterations.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# for python 2\n",
    "from __future__ import print_function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "%pylab inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "import numpy as np\n",
    "import theano\n",
    "import theano.tensor as T\n",
    "\n",
    "from lstm import load_data, prepare_data, batches_idx, lstm_layer, rmsprop\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model meta parameters\n",
    "\n",
    " - n_hidden: # of neurons in the LSTM layer\n",
    " - n_words: # of words in the dictionary. We use most frequent words. All other words are treated as unknown.\n",
    " - n_sample: max size (# of reviews) of the train dataset and the test dataset. (We may not be able to reach the max because if we want only reviews up to 50 words, there may be less than max such reviews in the whole data collection.)  \n",
    " - maxlen: max length in number of words for a review to be considered. Review longer than this will be ignored. This is also the # of recurrent steps.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "raw",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "n_words = 500\n",
    "n_sample = 1000\n",
    "maxlen = 50\n",
    "train, test, translate = load_data('./', n_words, n_sample, maxlen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(100000, 42)\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('../input/len20/a.raw.mod_para1_err1.format1')\n",
    "#df = df.iloc[np.random.permutation(len(df))]\n",
    "print(df.shape)\n",
    "\n",
    "ntrain=500\n",
    "ntest=100\n",
    "\n",
    "d = df[0:ntrain]\n",
    "train = (d.ix[:,:-1].values.tolist(), d.ix[:,-1].values.tolist())\n",
    "\n",
    "d = df[ntrain:ntrain+ntest]\n",
    "test = (d.ix[:,:-1].values.tolist(), d.ix[:,-1].values.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num of pos in train: 260 out of 500\n",
      "num of pos in test: 56 out of 100\n"
     ]
    }
   ],
   "source": [
    "print('num of pos in train:', numpy.sum(train[1]), 'out of', len(train[1]))\n",
    "print('num of pos in test:', numpy.sum(test[1]), 'out of', len(test[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "n_hidden=8\n",
    "n_words=7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def build_model(n_hidden, n_words):\n",
    "\n",
    "    x = T.matrix('x', dtype='int64')\n",
    "    mask = T.matrix('mask', dtype='float64')\n",
    "    y = T.vector('y', dtype='int64')\n",
    "\n",
    "    # embedding params\n",
    "    randn = numpy.random.rand(n_words, n_hidden)\n",
    "    Wemb = theano.shared(0.01 * randn)\n",
    "    \n",
    "    #lstm layer\n",
    "    lstm = lstm_layer(n_hidden)\n",
    "    \n",
    "    # classifier params\n",
    "    CU = theano.shared(0.01 * numpy.random.randn(n_hidden, 2))\n",
    "    Cb = theano.shared(numpy.zeros((2,)))\n",
    "    params = lstm.params + [Wemb, CU, Cb]\n",
    "    \n",
    "    \n",
    "    n_timesteps = x.shape[0]\n",
    "    n_samples = x.shape[1]\n",
    "\n",
    "    emb = Wemb[x.flatten()].reshape([n_timesteps, n_samples, n_hidden])\n",
    "    proj = lstm.calc_lstm(emb, mask)\n",
    "    proj = (proj * mask[:, :, None]).sum(axis=0)\n",
    "    proj = proj / mask.sum(axis=0)[:, None]\n",
    "\n",
    "    pred = T.nnet.softmax(T.dot(proj, CU) + Cb)\n",
    "\n",
    "    f_pred = theano.function([x, mask], pred.argmax(axis=1), name='f_pred')\n",
    "\n",
    "    off = 1e-8\n",
    "    cost = -T.log(pred[T.arange(n_samples), y] + off).mean()\n",
    "\n",
    "    return x, mask, y, params, cost, f_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "(x, mask, y, params, cost, f_pred) = build_model(n_hidden, n_words)\n",
    "grads = T.grad(cost, params)    \n",
    "\n",
    "lr = T.scalar(name='lr')\n",
    "f_grad_shared, f_update = rmsprop(lr, params, grads, x, mask, y, cost)\n",
    "\n",
    "lrate=0.1\n",
    "updates = [(p, p - lrate * g) for p, g in zip(params, grads)]\n",
    "f_sgd = theano.function([x, mask, y], cost, updates=updates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 2.07941498291 10 2.07663071891 20 2.07582285625 30 2.07570385552 40 2.07569136782 50 2.075691757 60 2.07569266502 70 2.0756930956 80 2.07569324665 90 2.07569327871 100 2.07569326435 110 2.07569323239 120 2.07569319379 130 2.07569315262 140 2.07569311041 150 2.07569306769 160 2.07569302467 170 2.07569298141 180 2.07569293792 190 2.0756928942 200 2.07569285025 210 2.07569280606 220 2.07569276161 230 2.07569271688 240 2.07569267188 250 2.07569262657 260 2.07569258096 270 2.07569253503 280 2.07569248876 290 2.07569244214 300 2.07569239516 310 2.0756923478 320 2.07569230006 330 2.07569225191 340 2.07569220334 350 2.07569215433 360 2.07569210488 370 2.07569205497 380 2.07569200457 390 2.07569195369 400 2.07569190229 410 2.07569185037 420 2.0756917979 430 2.07569174488 440"
     ]
    }
   ],
   "source": [
    "#nepoch = 200\n",
    "nepoch = 20000\n",
    "cc = numpy.zeros((nepoch,))\n",
    "\n",
    "sampling_iter = 50\n",
    "nepoch2 = int(nepoch / sampling_iter)\n",
    "cc2 = numpy.zeros((nepoch2,))\n",
    "cc2_idx = numpy.zeros((nepoch2,))\n",
    "\n",
    "\n",
    "\n",
    "t0 = time.time()\n",
    "for i in range(nepoch):\n",
    "    cost = 0\n",
    "    for train_index in batches_idx(len(train[0]), 200):\n",
    "        y = [train[1][t] for t in train_index]\n",
    "        x = [train[0][t] for t in train_index]\n",
    "        x, mask, y = prepare_data(x, y)\n",
    "        \n",
    "        cost += f_grad_shared(x, mask, y)\n",
    "        f_update(lrate)\n",
    "        #cost += f_sgd(x, mask, y)\n",
    "    \n",
    "    cc[i] = cost\n",
    "    if i % 10 == 0:\n",
    "        print(i, cost, end = ' ')\n",
    "        #print(i)\n",
    "\n",
    "    if i % sampling_iter == 0:\n",
    "        tx2, tmask2, ty2 = prepare_data(test[0], test[1])\n",
    "        py2 = f_pred(tx2, tmask2)\n",
    "        err_rate = 1.0*numpy.sum(numpy.abs(ty2 - py2))/len(test[0])\n",
    "        i2 = int(i / sampling_iter)\n",
    "        cc2[i2] = err_rate\n",
    "        cc2_idx[i2] = i\n",
    "        #print(i, err_rate)\n",
    "\n",
    "\n",
    "print('')\n",
    "print('run time:', (time.time()-t0)/60.0, \"minutes\")  #training time in min."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plot(cc[20:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "nx = 2\n",
    "ny = 1\n",
    "fig = plt.figure(figsize = [6 * nx, 4 * ny]) # inch\n",
    "\n",
    "ax0 = fig.add_subplot(ny, nx, 1)\n",
    "plot(cc)\n",
    "plt.legend(['training score'], loc='lower left')\n",
    "ax0.set_xlim(0)\n",
    "ax0.set_ylim(0)\n",
    "ax0.set_ylabel('training score')\n",
    "ax0.set_xlabel('epoch')\n",
    "\n",
    "ax1 = fig.add_subplot(ny, nx, 2)\n",
    "plot(cc2_idx, cc2, color='g')\n",
    "plt.legend(['test error'], loc='lower left')\n",
    "ax1.set_xlim(0)\n",
    "ax1.set_ylim(0, 1)\n",
    "ax1.set_ylabel('testing error')\n",
    "ax1.set_xlabel('epoch')\n",
    "\n",
    "fig.tight_layout()\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "format1_leng20_err0_500_100__different_RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "format1_leng20_err0_500_100__different_RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
