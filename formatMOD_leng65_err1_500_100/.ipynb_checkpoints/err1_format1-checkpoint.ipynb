{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## HW 3\n",
    "### Due Apr. 15th by end of day.\n",
    "### Name your notebook by firstname.lastname.hw3.ipynb and email it to zhang@csc.lsu.edu\n",
    "\n",
    "In this HW, we take a look at text processing using RNN based on LSTM. Given a review (hundred to thousand words long) about a movie, we want to classify the review as positive or negative (sentiment analysis). A model is given in this notebook that runs RNN, consisting of a single layer of LSTM cells, on the word sequence of the rewiews. Each review is transformed into a vector, which is the average of the LSTM vectors over the sequence. A softmax layer is then used to classify the reviews based on the LSTM vector representation. \n",
    "\n",
    "Your goal is to train the model and gain some idea on the computation challenge when training \"deep\" model for a large number of iterations.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# for python 2\n",
    "from __future__ import print_function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "%pylab inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "import numpy as np\n",
    "import theano\n",
    "import theano.tensor as T\n",
    "\n",
    "from lstm import load_data, prepare_data, batches_idx, lstm_layer, rmsprop\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model meta parameters\n",
    "\n",
    " - n_hidden: # of neurons in the LSTM layer\n",
    " - n_words: # of words in the dictionary. We use most frequent words. All other words are treated as unknown.\n",
    " - n_sample: max size (# of reviews) of the train dataset and the test dataset. (We may not be able to reach the max because if we want only reviews up to 50 words, there may be less than max such reviews in the whole data collection.)  \n",
    " - maxlen: max length in number of words for a review to be considered. Review longer than this will be ignored. This is also the # of recurrent steps.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "raw",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "n_words = 500\n",
    "n_sample = 1000\n",
    "maxlen = 50\n",
    "train, test, translate = load_data('./', n_words, n_sample, maxlen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(100000, 42)\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('../input/len20/a.raw.mod_para1_err1.format1')\n",
    "#df = df.iloc[np.random.permutation(len(df))]\n",
    "print(df.shape)\n",
    "\n",
    "ntrain=500\n",
    "ntest=100\n",
    "\n",
    "d = df[0:ntrain]\n",
    "train = (d.ix[:,:-1].values.tolist(), d.ix[:,-1].values.tolist())\n",
    "\n",
    "d = df[ntrain:ntrain+ntest]\n",
    "test = (d.ix[:,:-1].values.tolist(), d.ix[:,-1].values.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num of pos in train: 260 out of 500\n",
      "num of pos in test: 56 out of 100\n"
     ]
    }
   ],
   "source": [
    "print('num of pos in train:', numpy.sum(train[1]), 'out of', len(train[1]))\n",
    "print('num of pos in test:', numpy.sum(test[1]), 'out of', len(test[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "n_hidden=40\n",
    "n_words=7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def build_model(n_hidden, n_words):\n",
    "\n",
    "    x = T.matrix('x', dtype='int64')\n",
    "    mask = T.matrix('mask', dtype='float64')\n",
    "    y = T.vector('y', dtype='int64')\n",
    "\n",
    "    # embedding params\n",
    "    randn = numpy.random.rand(n_words, n_hidden)\n",
    "    Wemb = theano.shared(0.01 * randn)\n",
    "    \n",
    "    #lstm layer\n",
    "    lstm = lstm_layer(n_hidden)\n",
    "    \n",
    "    # classifier params\n",
    "    CU = theano.shared(0.01 * numpy.random.randn(n_hidden, 2))\n",
    "    Cb = theano.shared(numpy.zeros((2,)))\n",
    "    params = lstm.params + [Wemb, CU, Cb]\n",
    "    \n",
    "    \n",
    "    n_timesteps = x.shape[0]\n",
    "    n_samples = x.shape[1]\n",
    "\n",
    "    emb = Wemb[x.flatten()].reshape([n_timesteps, n_samples, n_hidden])\n",
    "    proj = lstm.calc_lstm(emb, mask)\n",
    "    proj = (proj * mask[:, :, None]).sum(axis=0)\n",
    "    proj = proj / mask.sum(axis=0)[:, None]\n",
    "\n",
    "    pred = T.nnet.softmax(T.dot(proj, CU) + Cb)\n",
    "\n",
    "    f_pred = theano.function([x, mask], pred.argmax(axis=1), name='f_pred')\n",
    "\n",
    "    off = 1e-8\n",
    "    cost = -T.log(pred[T.arange(n_samples), y] + off).mean()\n",
    "\n",
    "    return x, mask, y, params, cost, f_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "(x, mask, y, params, cost, f_pred) = build_model(n_hidden, n_words)\n",
    "grads = T.grad(cost, params)    \n",
    "\n",
    "lr = T.scalar(name='lr')\n",
    "f_grad_shared, f_update = rmsprop(lr, params, grads, x, mask, y, cost)\n",
    "\n",
    "lrate=0.1\n",
    "updates = [(p, p - lrate * g) for p, g in zip(params, grads)]\n",
    "f_sgd = theano.function([x, mask, y], cost, updates=updates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 2.07941350357 10 2.07662480751 20 2.0758198236 30 2.0757024242 40 2.07569014891 50 2.07569032956 60 2.07569094385 70 2.07569107204 "
     ]
    }
   ],
   "source": [
    "#nepoch = 200\n",
    "nepoch = 10000\n",
    "cc = numpy.zeros((nepoch,))\n",
    "\n",
    "sampling_iter = 50\n",
    "nepoch2 = int(nepoch / sampling_iter)\n",
    "cc2 = numpy.zeros((nepoch2,))\n",
    "cc2_idx = numpy.zeros((nepoch2,))\n",
    "\n",
    "\n",
    "\n",
    "t0 = time.time()\n",
    "for i in range(nepoch):\n",
    "    cost = 0\n",
    "    for train_index in batches_idx(len(train[0]), 200):\n",
    "        y = [train[1][t] for t in train_index]\n",
    "        x = [train[0][t] for t in train_index]\n",
    "        x, mask, y = prepare_data(x, y)\n",
    "        \n",
    "        cost += f_grad_shared(x, mask, y)\n",
    "        f_update(lrate)\n",
    "        #cost += f_sgd(x, mask, y)\n",
    "    \n",
    "    cc[i] = cost\n",
    "    if i % 10 == 0:\n",
    "        print(i, cost, end = ' ')\n",
    "        #print(i)\n",
    "\n",
    "    if i % sampling_iter == 0:\n",
    "        tx2, tmask2, ty2 = prepare_data(test[0], test[1])\n",
    "        py2 = f_pred(tx2, tmask2)\n",
    "        err_rate = 1.0*numpy.sum(numpy.abs(ty2 - py2))/len(test[0])\n",
    "        i2 = int(i / sampling_iter)\n",
    "        cc2[i2] = err_rate\n",
    "        cc2_idx[i2] = i\n",
    "        #print(i, err_rate)\n",
    "\n",
    "\n",
    "print('')\n",
    "print('run time:', (time.time()-t0)/60.0, \"minutes\")  #training time in min."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plot(cc[20:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "nx = 2\n",
    "ny = 1\n",
    "fig = plt.figure(figsize = [6 * nx, 4 * ny]) # inch\n",
    "\n",
    "ax0 = fig.add_subplot(ny, nx, 1)\n",
    "plot(cc)\n",
    "plt.legend(['training score'], loc='lower left')\n",
    "ax0.set_xlim(0)\n",
    "ax0.set_ylim(0)\n",
    "ax0.set_ylabel('training score')\n",
    "ax0.set_xlabel('epoch')\n",
    "\n",
    "ax1 = fig.add_subplot(ny, nx, 2)\n",
    "plot(cc2_idx, cc2, color='g')\n",
    "plt.legend(['test error'], loc='lower left')\n",
    "ax1.set_xlim(0)\n",
    "ax1.set_ylim(0, 1)\n",
    "ax1.set_ylabel('testing error')\n",
    "ax1.set_xlabel('epoch')\n",
    "\n",
    "fig.tight_layout()\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(np.min(cc))\n",
    "print(np.min(cc2))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
